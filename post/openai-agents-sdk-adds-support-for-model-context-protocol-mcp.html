<!DOCTYPE html><html><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><title data-next-head="">OpenAI Agents SDK Adds Support for Model Context Protocol (MCP)<!-- --> - The Tech Oracle by Elijah Mondero</title><meta name="description" content="OpenAI recently announced the integration of Model Context Protocol (MCP) into their Agents SDK. This addition bridges the gap between AI models and various data sources, making AI development more efficient and versatile." data-next-head=""/><meta name="keywords" content="OpenAI, Model Context Protocol, Agents SDK, AI Development" data-next-head=""/><link rel="icon" href="/favicon.ico" data-next-head=""/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-P05ETFHS5F"></script><script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){dataLayer.push(arguments);}
                gtag('js', new Date());
                gtag('config', 'G-P05ETFHS5F', {
                  page_path: window.location.pathname,
                });
              </script><link rel="preload" href="./_next/static/css/b362fc18b8b21f60.css" as="style"/><link rel="stylesheet" href="./_next/static/css/b362fc18b8b21f60.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="./_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="./_next/static/chunks/webpack-b5c0892378f1f10f.js" defer=""></script><script src="./_next/static/chunks/framework-16252ba0501bace7.js" defer=""></script><script src="./_next/static/chunks/main-9fdfc2eb0acc5c1d.js" defer=""></script><script src="./_next/static/chunks/pages/_app-20d8339bf96dffbf.js" defer=""></script><script src="./_next/static/chunks/414-1f47c83dc8c08102.js" defer=""></script><script src="./_next/static/chunks/236-d684b14885f6b4b8.js" defer=""></script><script src="./_next/static/chunks/pages/post/%5Bid%5D-4dde9effcfd19711.js" defer=""></script><script src="./_next/static/Ppr4zVApPAPkh7QSXR-JO/_buildManifest.js" defer=""></script><script src="./_next/static/Ppr4zVApPAPkh7QSXR-JO/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="App"><header class="App-header"><h1><a class="home-link" href="/">The Tech Oracle</a></h1><label class="switch"><input type="checkbox"/><span class="slider"></span></label></header><div class="blog-post-content"><img src="/posts/images/b83ba0c9-4e21-4ef7-b5c9-2c7f00c832aa.png" alt="OpenAI Agents SDK Adds Support for Model Context Protocol (MCP)" class="blog-post-image"/><div class="blog-post-text"><h2>OpenAI Agents SDK Adds Support for Model Context Protocol (MCP)</h2>&lt;p&gt;The OpenAI Agents SDK has recently integrated support for the Model Context Protocol (MCP), a significant advancement that bridges the gap between large language models (LLMs) and various data sources and tools. This article delves into the specifics of MCP, its implementations, and the potential benefits it brings to AI development.&lt;/p&gt;
&lt;h2&gt;What is MCP?&lt;/h2&gt;
&lt;p&gt;The Model Context Protocol (MCP) is an open protocol designed to standardize how applications provide context to LLMs. Similar to how USB-C standardizes connections between devices and peripherals, MCP provides a consistent way to connect AI models to different tools and data sources. This standardization simplifies the process of providing context to AI applications, enhancing their ability to perform complex tasks using external data and tools.&lt;/p&gt;
&lt;h2&gt;Implementing MCP in Agents SDK&lt;/h2&gt;
&lt;p&gt;The integration of MCP into the OpenAI Agents SDK means developers can now leverage a wide range of MCP servers to equip their AI agents with various tools. MCP servers can be categorized into two types based on their transport mechanism:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;stdio servers:&lt;/strong&gt; These servers run as a subprocess of your application, meaning they operate locally.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HTTP over SSE servers:&lt;/strong&gt; These servers run remotely and are accessed through a URL.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Developers can use the &lt;code&gt;MCPServerStdio&lt;/code&gt; and &lt;code&gt;MCPServerSse&lt;/code&gt; classes to connect to these servers and incorporate their tools into AI agents.&lt;/p&gt;
&lt;h3&gt;Using MCP Servers&lt;/h3&gt;
&lt;p&gt;MCP servers can be seamlessly added to agents in the SDK. Each time the agent runs, it queries the MCP server for a list of available tools, ensuring the LLM is aware of all the functionalities provided by the server. Here’s an example of integrating an MCP server:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;agent = Agent(
    name=&quot;Assistant&quot;,
    instructions=&quot;Use the tools to achieve the task&quot;,
    mcp_servers=[mcp_server_1, mcp_server_2]
)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Caching and Performance Optimization&lt;/h3&gt;
&lt;p&gt;To reduce latency, especially when using remote servers, the SDK allows for caching the list of tools provided by an MCP server. By passing &lt;code&gt;cache_tools_list=True&lt;/code&gt; to &lt;code&gt;MCPServerStdio&lt;/code&gt; and &lt;code&gt;MCPServerSse&lt;/code&gt;, developers can ensure the agent retrieves the tool list quickly without repeated calls to the server.&lt;/p&gt;
&lt;h2&gt;Benefits of MCP Integration&lt;/h2&gt;
&lt;p&gt;The inclusion of MCP in the OpenAI Agents SDK provides several benefits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Standardization:&lt;/strong&gt; MCP offers a uniform way to connect LLMs to various tools and data sources, streamlining the development process.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flexibility:&lt;/strong&gt; Developers can choose between local and remote MCP servers based on their application requirements.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Efficiency:&lt;/strong&gt; Tool caching and efficient querying reduce latency and improve overall performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The support for MCP within the OpenAI Agents SDK marks a significant milestone in AI development. By standardizing how context is provided to LLMs, MCP simplifies the process of integrating complex tools and data sources, thereby enriching the capabilities of AI agents. As AI continues to evolve, protocols like MCP will play a crucial role in advancing the field and unlocking new possibilities.&lt;/p&gt;
&lt;p&gt;For more information, visit the &lt;a href=&quot;https://openai.github.io/openai-agents-python/mcp/&quot;&gt;OpenAI Agents SDK documentation&lt;/a&gt;.&lt;/p&gt;<p class="meta"><strong>Posted by:</strong> <!-- -->Elijah Mondero</p><p class="meta"><strong>Tags:</strong> <!-- -->OpenAI, Model Context Protocol, Agents SDK, AI Development</p></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"id":"openai-agents-sdk-adds-support-for-model-context-protocol-mcp","title":"OpenAI Agents SDK Adds Support for Model Context Protocol (MCP)","date":"2025-03-27T07:27:18.506108Z","contentHtml":"\u003cp\u003eThe OpenAI Agents SDK has recently integrated support for the Model Context Protocol (MCP), a significant advancement that bridges the gap between large language models (LLMs) and various data sources and tools. This article delves into the specifics of MCP, its implementations, and the potential benefits it brings to AI development.\u003c/p\u003e\n\u003ch2\u003eWhat is MCP?\u003c/h2\u003e\n\u003cp\u003eThe Model Context Protocol (MCP) is an open protocol designed to standardize how applications provide context to LLMs. Similar to how USB-C standardizes connections between devices and peripherals, MCP provides a consistent way to connect AI models to different tools and data sources. This standardization simplifies the process of providing context to AI applications, enhancing their ability to perform complex tasks using external data and tools.\u003c/p\u003e\n\u003ch2\u003eImplementing MCP in Agents SDK\u003c/h2\u003e\n\u003cp\u003eThe integration of MCP into the OpenAI Agents SDK means developers can now leverage a wide range of MCP servers to equip their AI agents with various tools. MCP servers can be categorized into two types based on their transport mechanism:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003estdio servers:\u003c/strong\u003e These servers run as a subprocess of your application, meaning they operate locally.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eHTTP over SSE servers:\u003c/strong\u003e These servers run remotely and are accessed through a URL.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDevelopers can use the \u003ccode\u003eMCPServerStdio\u003c/code\u003e and \u003ccode\u003eMCPServerSse\u003c/code\u003e classes to connect to these servers and incorporate their tools into AI agents.\u003c/p\u003e\n\u003ch3\u003eUsing MCP Servers\u003c/h3\u003e\n\u003cp\u003eMCP servers can be seamlessly added to agents in the SDK. Each time the agent runs, it queries the MCP server for a list of available tools, ensuring the LLM is aware of all the functionalities provided by the server. Here’s an example of integrating an MCP server:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-python\"\u003eagent = Agent(\n    name=\"Assistant\",\n    instructions=\"Use the tools to achieve the task\",\n    mcp_servers=[mcp_server_1, mcp_server_2]\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eCaching and Performance Optimization\u003c/h3\u003e\n\u003cp\u003eTo reduce latency, especially when using remote servers, the SDK allows for caching the list of tools provided by an MCP server. By passing \u003ccode\u003ecache_tools_list=True\u003c/code\u003e to \u003ccode\u003eMCPServerStdio\u003c/code\u003e and \u003ccode\u003eMCPServerSse\u003c/code\u003e, developers can ensure the agent retrieves the tool list quickly without repeated calls to the server.\u003c/p\u003e\n\u003ch2\u003eBenefits of MCP Integration\u003c/h2\u003e\n\u003cp\u003eThe inclusion of MCP in the OpenAI Agents SDK provides several benefits:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eStandardization:\u003c/strong\u003e MCP offers a uniform way to connect LLMs to various tools and data sources, streamlining the development process.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFlexibility:\u003c/strong\u003e Developers can choose between local and remote MCP servers based on their application requirements.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEfficiency:\u003c/strong\u003e Tool caching and efficient querying reduce latency and improve overall performance.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eConclusion\u003c/h2\u003e\n\u003cp\u003eThe support for MCP within the OpenAI Agents SDK marks a significant milestone in AI development. By standardizing how context is provided to LLMs, MCP simplifies the process of integrating complex tools and data sources, thereby enriching the capabilities of AI agents. As AI continues to evolve, protocols like MCP will play a crucial role in advancing the field and unlocking new possibilities.\u003c/p\u003e\n\u003cp\u003eFor more information, visit the \u003ca href=\"https://openai.github.io/openai-agents-python/mcp/\"\u003eOpenAI Agents SDK documentation\u003c/a\u003e.\u003c/p\u003e\n","excerpt":"OpenAI recently announced the integration of Model Context Protocol (MCP) into their Agents SDK. This addition bridges the gap between AI models and various data sources, making AI development more efficient and versatile.","postedBy":"Elijah Mondero","tags":["OpenAI","Model Context Protocol","Agents SDK","AI Development"],"image_path":"/posts/images/b83ba0c9-4e21-4ef7-b5c9-2c7f00c832aa.png"}},"__N_SSG":true},"page":"/post/[id]","query":{"id":"openai-agents-sdk-adds-support-for-model-context-protocol-mcp"},"buildId":"Ppr4zVApPAPkh7QSXR-JO","assetPrefix":".","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>